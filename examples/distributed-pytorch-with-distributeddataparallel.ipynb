{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "Licensed under the MIT License.\n",
        "Modified by Shohei Nagata, 1st April 2021."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PyTorchの分散学習 (DistributedDataParallel版)\n",
        "本日のハンズオンでは[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)データセットを対象に、PyTorchの`DistributedDataParallel`モジュールを用いてGPUクラスター間で分散学習を行い、PyTorchモデルを学習します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 前提条件確認\n",
        "\n",
        "事前にAzure Machine Learning Python SDKをインストールし、Azure ML `Workspace`を作成してください。  \n",
        "※Azure Machine Learning Notebook VMを使用している場合は、すべての設定が完了しています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Azure ML SDKのバージョン確認\n",
        "import azureml.core\n",
        "\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ワークスペースの設定\n",
        "Azure ML ワークスペースによってAzure MLで使用するアセット類 (データ、スクリプト、出力、等々)を管理していきます。\n",
        "![](https://docs.microsoft.com/ja-jp/azure/machine-learning/media/concept-azure-machine-learning-architecture/architecture.svg)\n",
        "\n",
        "前提条件のステップで作成した既存のワークスペースから、[Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace)オブジェクトを初期化します。`Workspace.from_config()` は、`config.json` に格納された詳細情報から、ワークスペース・オブジェクトを作成します。   \n",
        "\n",
        "事前にAzure ML Studioから構成ファイル (config.json)をダウンロードし、本スクリプトと同一階層に置きます。  \n",
        "\n",
        "初回実行時は認証を行う必要があるため、実行結果部分の指示に従って https://microsoft.com/devicelogin にアクセスし、認証コードを入力します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core.workspace import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep='\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 計算環境の準備\n",
        "\n",
        "モデルをトレーニングするためには、[コンピューティング先](hhttps://docs.microsoft.com/ja-jp/azure/machine-learning/concept-azure-machine-learning-architecture#computes)を作成する必要があります。このノートブックでは、コンピューティング クラスターをリモートトレーニング用のコンピュートリソースとして使用します。  \n",
        "具体的には，以下のコードで，`STANDARD_NC6`のGPUクラスターを作成し，`0`から`4`のノードにオートスケールします。\n",
        "\n",
        "**コンピューティングクラスターの作成には約5分かかります。** 同一名称のものがワークスペースにある場合、下記コードは作成プロセスをスキップします。\n",
        "\n",
        "他のAzureサービスと同様に、Azure Machine Learningサービスに関連する特定のリソース（コンピューティング インスタンス、コンピューティング クラスターなど）には制限があります。  \n",
        "参考：[Azure Machine Learning を使用するリソースのクォータの管理と引き上げ](https://docs.microsoft.com/ja-jp/azure/machine-learning/how-to-manage-quotas)、\n",
        "[申請手順](https://docs.microsoft.com/ja-jp/azure/azure-portal/supportability/regional-quota-requests#request-a-quota-increase-by-region-from-help--support)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# choose a name for your cluster\n",
        "cluster_name = 'gpu-cluster'\n",
        "\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing compute target.')\n",
        "except ComputeTargetException:\n",
        "    print('Creating a new compute target...')\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', # 使用するVMインスタンスを指定します.  (Standard_NC6s_v3)\n",
        "                                                           max_nodes=2)\n",
        "\n",
        "    # create the cluster\n",
        "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "\n",
        "    compute_target.wait_for_completion(show_output=True)\n",
        "\n",
        "# use get_status() to get a detailed status for the current AmlCompute. \n",
        "print(compute_target.get_status().serialize())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## データセットの準備\n",
        "\n",
        "学習に使用するデータセットを準備します。まず、cs.toronto.eduのサイトから公開されているCIFAR-10データセットをダウンロードして抽出し、Azure ML FileDatasetを作成して学習に使用します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CIFAR-10 データのダウンロードと解凍"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import urllib\n",
        "import tarfile\n",
        "import os\n",
        "\n",
        "url = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
        "filename = 'cifar-10-python.tar.gz'\n",
        "data_root = 'cifar-10'\n",
        "filepath = os.path.join(data_root, filename)\n",
        "\n",
        "if not os.path.isdir(data_root):\n",
        "    os.makedirs(data_root, exist_ok=True)\n",
        "    urllib.request.urlretrieve(url, filepath)\n",
        "    with tarfile.open(filepath, \"r:gz\") as tar:\n",
        "        tar.extractall(path=data_root)\n",
        "    os.remove(filepath)  # delete tar.gz file after extraction\n",
        "elif not os.path.isdir(data_root + \"/cifar-10-batches-py\"): #解凍だけされていない場合\n",
        "    with tarfile.open(filepath, \"r:gz\") as tar:\n",
        "        tar.extractall(path=data_root)\n",
        "    os.remove(filepath)  # delete tar.gz file after extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Azure MLデータセットの作成\n",
        "\n",
        "`upload_directory`メソッドは、データストアにデータをアップロードし、そこからFileDatasetを作成します。このチュートリアルでは、ワークスペースのデフォルトのデータストアを使用します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "datastore = ws.get_default_datastore()\n",
        "dataset = Dataset.File.upload_directory(\n",
        "    src_dir=data_root, target=(datastore, data_root + \"_test\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## リモートでのモデル学習 \n",
        "リモート (Azure ML上の)計算環境が準備できたので、分散学習ジョブを実行してみましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### プロジェクトディレクトリの作成\n",
        "ローカルマシンからリモートリソースにアクセスするために必要なコードをすべて格納するディレクトリを作成します。このディレクトリには、トレーニングスクリプトと、トレーニングスクリプトが依存する追加ファイルが含まれます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "project_folder = './pytorch-distr'\n",
        "os.makedirs(project_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### トレーニングスクリプトの準備\n",
        "ここでは、トレーニング用のスクリプトを作成します。このチュートリアルでは、CIFAR-10の分散学習用のスクリプトを`train.py`で用意しています。実際には、カスタムのPyTorchトレーニングスクリプトをそのまま使用して、コードを変更することなくAzure MLで実行することが可能です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "トレーニングスクリプト `train.py`をプロジェクトディレクトリ内へコピーします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "shutil.copy('train.py', project_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 実験の作成\n",
        "[実験 (Experiment)](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment)を作成して、この分散PyTorchチュートリアルのワークスペースでのすべての実行を追跡します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Experiment\n",
        "\n",
        "experiment_name = 'pytorch-distr'\n",
        "experiment = Experiment(ws, name=experiment_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 環境の作成\n",
        "\n",
        "Azure MLではいくつかの[キュレートされた実行環境](https://docs.microsoft.com/ja-jp/azure/machine-learning/how-to-use-environments#use-a-curated-environment)が用意されています。\n",
        "今回はPyTorch 1.6 GPU環境を使用します。こちらのキュレートされた環境には今回のトレーニングスクリプトで必要なtorch, torchvisionも含まれています。\n",
        "\n",
        "参考：[キュレーションされた環境一覧](https://docs.microsoft.com/ja-jp/azure/machine-learning/resource-curated-environments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Environment\n",
        "\n",
        "pytorch_env = Environment.get(ws, name='AzureML-PyTorch-1.6-GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 中身の確認\n",
        "print(pytorch_env.python.conda_dependencies.serialize_to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### トレーニングジョブの設定\n",
        "`ScriptRunConfig`を用いてスクリプトの実行構成を作成します。\n",
        "![](../img/scriptrunconfig.png)\n",
        "\n",
        "参考：[スクリプトの実行構成を作成する](https://docs.microsoft.com/ja-jp/azure/machine-learning/how-to-set-up-training-targets#create-the-script-run-configuration)\n",
        "\n",
        "#### 分散ジョブの構成を指定する\n",
        "分散トレーニング ジョブを実行する場合は、分散ジョブ固有の構成を `distributed_job_config` パラメーターに指定します。 \n",
        "\n",
        "\n",
        "Azure MLで分散PyTorchジョブを開始するには、次の2つの方法があります。\n",
        "\n",
        "1. プロセスごとの起動 - 実行するワーカープロセスの総数を指定します (通常、GPUごとに1つ)。\n",
        "Azure ML によって各プロセスの起動が処理されます。\n",
        "2. [torch.distributed.launch](https://pytorch.org/docs/stable/distributed.html#launch-utility) を使ったノード単位の起動 - 各ノードで実行したい「torch.distributed.launch」コマンドを指定します。Torch 起動ユーティリティによって、各ノードのワーカー プロセスの起動が処理されます。\n",
        "\n",
        "これらの起動オプションには、基本的な違いはありません。\n",
        "詳細は[ドキュメント](https://docs.microsoft.com/ja-jp/azure/machine-learning/how-to-train-pytorch#distributeddataparallel)を参照してください。\n",
        "\n",
        "両方のオプションを以下に示します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### プロセスごとの起動\n",
        "\n",
        "トレーニングスクリプトを実行するための各プロセスの起動をAzure MLが処理して分散 PyTorch ジョブを実行するには、次の操作を行います。\n",
        "\n",
        "1. トレーニング スクリプトと引数を指定します。\n",
        "2. `PyTorchConfiguration` を作成し、`process_count` と `node_count` を指定します。 `process_count` は、ジョブに対して実行するプロセスの合計数に対応しています。 これは通常、ノードあたりの GPU の数にノード数を掛けた値と同じにします。 `process_count` を指定しないと、Azure ML では、既定でノードごとに 1 つのプロセスが起動されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import ScriptRunConfig\n",
        "from azureml.core.runconfig import PyTorchConfiguration\n",
        "\n",
        "# create distributed config\n",
        "distr_config = PyTorchConfiguration(process_count=2, node_count=2)\n",
        "\n",
        "# create args\n",
        "args = [\"--data-dir\", dataset.as_download(), \"--epochs\", 25]\n",
        "\n",
        "# create job config\n",
        "src = ScriptRunConfig(source_directory=project_folder,\n",
        "                      script='train.py',\n",
        "                      arguments=args,\n",
        "                      compute_target=compute_target,\n",
        "                      environment=pytorch_env,\n",
        "                      distributed_job_config=distr_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### `torch.distributed.launch` によるノード毎の起動\n",
        "\n",
        "もし、PyTorchが提供する起動ユーティリティー `torch.distributed.launch` を使って、各ノードのワーカープロセスの起動を処理したい場合は、以下のようにしても構いません。\n",
        "\n",
        "1. ScriptRunConfigの`command`パラメータにlaunchコマンドを指定します。PyTorch のジョブの場合、Azure ML は各ノードに環境変数 `MASTER_ADDR`, `MASTER_PORT`, `NODE_RANK` を設定しますので、コマンドの中でこれらの環境変数を参照すればよいのです。GPU数が1以上のSKUを使用している場合は、`--nproc_per_node`の引数を適宜調整してください。\n",
        "\n",
        "2. `PyTorchConfiguration`を作成し、`node_count`を指定します。デフォルトでは、Azure MLはノードごとに1つのプロセスを起動して、指定した`コマンド`を実行しますので、`process_count`を指定する必要はありません。\n",
        "\n",
        "以下のコードをコメントアウト解除して、この方法でジョブを設定してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "from azureml.core import ScriptRunConfig\n",
        "from azureml.core.runconfig import PyTorchConfiguration\n",
        "\n",
        "# create distributed config\n",
        "distr_config = PyTorchConfiguration(node_count=2)\n",
        "\n",
        "# define command\n",
        "launch_cmd = [\"python -m torch.distributed.launch --nproc_per_node 1 --nnodes 2 \" \\\n",
        "    \"--node_rank $NODE_RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT --use_env \" \\\n",
        "    \"train.py --data-dir\", dataset.as_download(), \"--epochs 25\"]\n",
        "\n",
        "# create job config\n",
        "src = ScriptRunConfig(source_directory=project_folder,\n",
        "                      command=launch_cmd,\n",
        "                      compute_target=compute_target,\n",
        "                      environment=pytorch_env,\n",
        "                      distributed_job_config=distr_config)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### トレーニングジョブの実行 (送信)\n",
        "前項の`ScriptRunConfig`で設定した条件に基づいて実験を実行 (送信)します。\n",
        "Run your experiment by submitting your `ScriptRunConfig` object. Note that this call is asynchronous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run = experiment.submit(src)\n",
        "print(run)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### モニタリング\n",
        "Jupyterウィジェットを使って実行の進捗状況を監視することができます。実行のサブミッションと同様に、ウィジェットは非同期で、ジョブが完了するまで10～15秒ごとに自動で更新されます。ウィジェットでは、Azure MLの実行に記録した損失指標が自動的に表示・可視化されます。\n",
        "\n",
        "※VSCode上で実行する場合、テーマ設定 (背景色)によってはAzure MLウィジェットが見えにくくなる可能性があります。その場合はLightテーマの使用をお勧めします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.widgets import RunDetails\n",
        "\n",
        "RunDetails(run).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "また、スクリプトのトレーニングが完了するまでノートブックの実行をブロックしてから、さらにそれ以降のコードを実行していく形にもできます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "run.wait_for_completion(show_output=True) # this provides a verbose log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## モデルの登録\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#実行に関係しているファイル一覧の表示\n",
        "for i in run.get_file_names():\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = run.register_model(model_name = 'pytorch-distr', model_path = 'outputs/cifar_net.pt')\n",
        "print(model.name, model.id, model.version, sep = '\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## モデルデプロイ\n",
        "Azure Container Instances (ACI) にモデルをWebサービスとしてモデルをデプロイしていきます。  \n",
        "参考：[Azure Container Instances とは](https://docs.microsoft.com/ja-jp/azure/container-instances/container-instances-overview)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### スコアリングスクリプトの作成\n",
        "Web サービスの呼び出しに使用される score.py というスコアリング スクリプトを作成してモデルの使用方法を示します。\n",
        "スコアリング スクリプトには、2 つの必要な関数を含める必要があります。\n",
        "- `init()` 関数。通常、グローバル オブジェクトにモデルを読み込みます。 この関数は、Docker コンテナーを開始するときに 1 回だけ実行されます。\n",
        "- `run(input_data)` 関数。モデルを使用して、入力データに基づく値を予測します。 実行に対する入力と出力は、通常、JSON を使用してシリアル化およびシリアル化解除が実行されますが、その他の形式もサポートされています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile score.py\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "\n",
        "from azureml.core.model import Model\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3) # in_channels, out_channels, kernel_size, \n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3)\n",
        "        self.fc1 = nn.Linear(128 * 6 * 6, 120)\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 128 * 6 * 6)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def init():\n",
        "    global model\n",
        "    # AZUREML_MODEL_DIR is an environment variable created during deployment.\n",
        "    # It is the path to the model folder (./azureml-models/$MODEL_NAME/$VERSION)\n",
        "    # For multiple models, it points to the folder containing all deployed models (./azureml-models)\n",
        "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'cifar_net.pt')\n",
        "    model = Net()    \n",
        "    model.load_state_dict(torch.load(model_path,map_location=torch.device('cpu')))\n",
        "    model.eval()\n",
        "\n",
        "def run(input_data):\n",
        "    input_data = torch.tensor(json.loads(input_data)['data'])\n",
        "\n",
        "    # get prediction\n",
        "    with torch.no_grad():\n",
        "        input_data = input_data.unsqueeze(0) # add batch dimension\n",
        "        output = model(input_data) \n",
        "        classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "        softmax = nn.Softmax(dim=1)\n",
        "        pred_probs = softmax(output).numpy()[0]\n",
        "        index = torch.argmax(output, 1) \n",
        "\n",
        "    result = {\"label\": classes[index], \"probability\": str(pred_probs[index])}\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ACIコンテナへのデプロイ\n",
        "デプロイの構成ファイルを作成し、ACI コンテナーに必要な CPU 数と RAM ギガバイト数を指定します。 実際のモデルにもよりますが、通常、多くのモデルには既定値の 1 コアと 1 ギガバイトの RAM で十分です。 後でもっと必要になった場合は、イメージを再作成し、サービスをデプロイし直す必要があります。\n",
        "※今回はデプロイ先の実行環境にはトレーニング時と同一の環境を使用しています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "from azureml.core.webservice import AciWebservice\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import Webservice\n",
        "from azureml.core.model import Model\n",
        "\n",
        "#推論スクリプト・環境の指定\n",
        "inference_config = InferenceConfig(entry_script=\"score.py\", environment=pytorch_env) # 学習時と同じ環境を使用\n",
        "\n",
        "#デプロイの構成設定\n",
        "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
        "                                               memory_gb=1, \n",
        "                                               tags={'data': 'cifar-10',  'model':'pytorch-distr', 'framework':'pytorch'},\n",
        "                                               description='Classify daily objects from the cifar-10 dataset using PyTorch')\n",
        "\n",
        "model = Model(ws, 'pytorch-distr')\n",
        "\n",
        "service = Model.deploy(workspace=ws, \n",
        "                           name='aci-cifar10', \n",
        "                           models=[model], \n",
        "                           inference_config=inference_config, \n",
        "                           deployment_config=aciconfig,\n",
        "                           overwrite=True)\n",
        "\n",
        "service.wait_for_deployment(show_output=True)\n",
        "print(service.state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # デプロイ中に問題が発生した場合にログ取得\n",
        "# service.get_logs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # 再デプロイ前に既存のACIサービスを削除\n",
        "# service.delete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Webサービスのテスト\n",
        "最後に、デプロイしたWebサービスをテストしてみましょう。ACIにホストされているWebサービスにJSON文字列としてデータを送信し、SDKのrun APIを使ってサービスを呼び出してみます。ここでは、検証データから画像を取り出して予測を行います。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # 既存のACIWebサービスを取得する場合. serviceを定義する。\n",
        "# from azureml.core.workspace import Workspace\n",
        "# from azureml.core.webservice import AciWebservice\n",
        "# ws = Workspace.from_config()\n",
        "# service = AciWebservice(workspace=ws, name='aci-cifar10')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CIFAR-10 データセット内のテスト画像を用いて推論を行う\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "test_dataset = CIFAR10(root=\"cifar-10\", train=False, download=False, transform=transform)\n",
        "image_tensor, target_class = test_dataset[99] #数字で対象画像を指定\n",
        "image_np = image_tensor.to('cpu').detach().numpy()\n",
        "input_data = image_np\n",
        "\n",
        "# plot image\n",
        "plt.axis('off')\n",
        "plt.imshow(image_tensor.permute(1, 2, 0))\n",
        "plt.show()\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "print(classes[target_class])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ACIへ送信して推論実行\n",
        "result = service.run(input_data=json.dumps({'data': input_data.tolist()}))\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## クリーンアップ\n",
        "最後に、デプロイされたWebサービスを削除します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "service.delete()"
      ]
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "minxia"
      }
    ],
    "category": "training",
    "compute": [
      "AML Compute"
    ],
    "datasets": [
      "CIFAR-10"
    ],
    "deployment": [
      "None"
    ],
    "exclude_from_index": false,
    "framework": [
      "PyTorch"
    ],
    "friendly_name": "Distributed training with PyTorch",
    "index_order": 1,
    "kernelspec": {
      "display_name": "Python 3.6.13 64-bit ('notebook_env3': conda)",
      "name": "python3613jvsc74a57bd0073e72342da3ad431f6a3c40df7c6afcfd107d7750244573f2bb23bb467f8b99"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "tags": [
      "None"
    ],
    "task": "Train a model using distributed training via PyTorch DistributedDataParallel"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}